{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T11:17:37.406627Z",
     "start_time": "2025-12-26T11:17:37.405049Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "26f630d3009cdcd2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T11:17:39.506160Z",
     "start_time": "2025-12-26T11:17:37.462405Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import math\n",
    "import random\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models, callbacks\n",
    "from tensorflow.keras.layers import Dense, Flatten, GlobalAveragePooling2D, Input, Conv2D, MaxPooling2D, Dropout, Rescaling\n",
    "from tensorflow.keras.models import Model, load_model, Sequential\n",
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from hyperopt import hp, fmin, tpe, rand, STATUS_OK, Trials\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(f\"TensorFlow Version: {tf.__version__}\")\n",
    "\n",
    "# --- 1. DATA LOADING (SPARSE / INTEGER MODE) ---\n",
    "# This mode is safer and fixes the Shape Mismatch error\n",
    "TARGET_SIZE = (224, 224)\n",
    "INPUT_SHAPE = (224, 224, 3)\n",
    "BATCHSIZE = 32\n",
    "\n",
    "# Load Training Data (Int Mode)\n",
    "train_raw = image_dataset_from_directory(\n",
    "    './train_224/',\n",
    "    image_size=TARGET_SIZE,\n",
    "    batch_size=BATCHSIZE,\n",
    "    label_mode='int',  # <--- Changed to 'int' to match your error shape (None, 1)\n",
    "    shuffle=True,\n",
    "    seed=123\n",
    ")\n",
    "\n",
    "# Load Validation Data (Int Mode)\n",
    "val_raw = image_dataset_from_directory(\n",
    "    './test_224/',\n",
    "    image_size=TARGET_SIZE,\n",
    "    batch_size=BATCHSIZE,\n",
    "    label_mode='int',  # <--- Changed to 'int'\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "class_names = train_raw.class_names\n",
    "NUM_CLASSES = len(class_names)\n",
    "print(f\"Classes: {class_names} (Total: {NUM_CLASSES})\")\n",
    "\n",
    "# Normalization\n",
    "normalization_layer = Rescaling(1./255)\n",
    "train_ds = train_raw.map(lambda x, y: (normalization_layer(x), y)).cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "val_ds = val_raw.map(lambda x, y: (normalization_layer(x), y)).cache().prefetch(buffer_size=tf.data.AUTOTUNE)"
   ],
   "id": "f255e087e57154f1",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-26 14:47:37.896832: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-12-26 14:47:37.897091: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-12-26 14:47:37.930947: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-12-26 14:47:38.747315: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-12-26 14:47:38.747547: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "/usr/local/lib/python3.12/site-packages/keras/src/export/tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(np, \"object\"):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 2.20.0\n",
      "Found 287 files belonging to 5 classes.\n",
      "Found 75 files belonging to 4 classes.\n",
      "Classes: ['0', '1', '2', '3', '4'] (Total: 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohammad/.local/lib/python3.12/site-packages/hyperopt/atpe.py:19: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n",
      "2025-12-26 14:47:39.416729: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T11:17:39.518889Z",
     "start_time": "2025-12-26T11:17:39.513860Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# --- 2. CALLBACKS ---\n",
    "class LossHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses = {'batch':[], 'epoch':[]}\n",
    "        self.accuracy = {'batch':[], 'epoch':[]}\n",
    "        self.val_loss = {'batch':[], 'epoch':[]}\n",
    "        self.val_acc = {'batch':[], 'epoch':[]}\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        self.losses['batch'].append(logs.get('loss'))\n",
    "        self.accuracy['batch'].append(logs.get('accuracy'))\n",
    "        self.val_loss['batch'].append(logs.get('val_loss'))\n",
    "        self.val_acc['batch'].append(logs.get('val_accuracy'))\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.losses['epoch'].append(logs.get('loss'))\n",
    "        self.accuracy['epoch'].append(logs.get('accuracy'))\n",
    "        self.val_loss['epoch'].append(logs.get('val_loss'))\n",
    "        self.val_acc['epoch'].append(logs.get('val_accuracy'))\n",
    "    def loss_plot(self, loss_type):\n",
    "        iters = range(len(self.losses[loss_type]))\n",
    "        plt.figure()\n",
    "        if loss_type == 'epoch':\n",
    "            plt.plot(iters, self.accuracy[loss_type], 'r', label='train acc')\n",
    "            plt.plot(iters, self.losses[loss_type], 'g', label='train loss')\n",
    "            plt.plot(iters, self.val_acc[loss_type], 'b', label='val acc')\n",
    "            plt.plot(iters, self.val_loss[loss_type], 'k', label='val loss')\n",
    "        plt.show()\n",
    "\n",
    "history_this = LossHistory()"
   ],
   "id": "79f15343b06fb23b",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T11:21:38.089091Z",
     "start_time": "2025-12-26T11:17:39.564297Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- Updated VGG16 Function to Show Progress ---\n",
    "\n",
    "def vgg16(num_class, epochs=20, frozen=15, lr=0.001, patience=2, dropout_rate=0.5, verbose=1, savepath='./VGG16.h5', history=history_this, input_shape=INPUT_SHAPE):\n",
    "    # Check for weights file (force download if needed or use local)\n",
    "    weights_path = './vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "    if os.path.exists(weights_path):\n",
    "        print(f\"Loading weights from {weights_path}\")\n",
    "        base_model = VGG16(include_top=False, weights=weights_path, input_shape=input_shape)\n",
    "    else:\n",
    "        print(\"Local weights not found, downloading from ImageNet...\")\n",
    "        base_model = VGG16(include_top=False, weights='imagenet', input_shape=input_shape)\n",
    "\n",
    "    # Freeze layers\n",
    "    for layer in base_model.layers[:frozen]:\n",
    "        layer.trainable = False\n",
    "    for layer in base_model.layers[frozen:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    predictions = Dense(num_class, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=predictions, name='vgg16')\n",
    "\n",
    "    # Use legacy Adam optimizer for M1/M2 Macs if needed, otherwise standard\n",
    "    opt = Adam(learning_rate=lr)\n",
    "\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "    # Callbacks\n",
    "    earlyStopping = callbacks.EarlyStopping(\n",
    "        monitor='val_accuracy',\n",
    "        patience=patience,\n",
    "        verbose=1,\n",
    "        mode='max',\n",
    "        restore_best_weights=True # Important: keeps the best model, not the last one\n",
    "    )\n",
    "\n",
    "    saveBestModel = callbacks.ModelCheckpoint(\n",
    "        filepath=savepath,\n",
    "        monitor='val_accuracy',\n",
    "        verbose=1,\n",
    "        save_best_only=True,\n",
    "        mode='max'\n",
    "    )\n",
    "\n",
    "    print(f\"Starting training for {epochs} epochs...\")\n",
    "\n",
    "    # Train\n",
    "    hist = model.fit(\n",
    "        train_ds,\n",
    "        epochs=epochs,\n",
    "        validation_data=val_ds,\n",
    "        callbacks=[earlyStopping, saveBestModel, history],\n",
    "        verbose=1  # verbose=1 shows the progress bar [======]\n",
    "    )\n",
    "    return hist\n",
    "\n",
    "# --- Execution Cell ---\n",
    "\n",
    "# Run the training\n",
    "# We use fewer epochs (5) just to test if the progress bar appears\n",
    "print(\"Training VGG16...\")\n",
    "vgg16(num_class=NUM_CLASSES, frozen=15, epochs=15, patience=3, lr=0.001, dropout_rate=0.5, verbose=1)\n",
    "\n",
    "# Plot the results\n",
    "print(\"Plotting results...\")\n",
    "history_this.loss_plot('epoch')\n",
    "history_this.loss_plot('batch')"
   ],
   "id": "592003b4e12c38bd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training VGG16...\n",
      "Loading weights from ./vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "Starting training for 15 epochs...\n",
      "Epoch 1/15\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4s/step - accuracy: 0.6861 - loss: 0.9821\n",
      "Epoch 1: val_accuracy improved from None to 0.96000, saving model to ./VGG16.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: finished saving model to ./VGG16.h5\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m51s\u001B[0m 6s/step - accuracy: 0.7979 - loss: 0.7462 - val_accuracy: 0.9600 - val_loss: 0.0726\n",
      "Epoch 2/15\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4s/step - accuracy: 0.8917 - loss: 0.2307\n",
      "Epoch 2: val_accuracy improved from 0.96000 to 1.00000, saving model to ./VGG16.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2: finished saving model to ./VGG16.h5\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m47s\u001B[0m 5s/step - accuracy: 0.9164 - loss: 0.2032 - val_accuracy: 1.0000 - val_loss: 0.0259\n",
      "Epoch 3/15\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4s/step - accuracy: 0.9759 - loss: 0.0807\n",
      "Epoch 3: val_accuracy did not improve from 1.00000\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m46s\u001B[0m 5s/step - accuracy: 0.9652 - loss: 0.0958 - val_accuracy: 1.0000 - val_loss: 0.0011\n",
      "Epoch 4/15\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4s/step - accuracy: 0.9711 - loss: 0.1199\n",
      "Epoch 4: val_accuracy did not improve from 1.00000\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m46s\u001B[0m 5s/step - accuracy: 0.9721 - loss: 0.0770 - val_accuracy: 0.9867 - val_loss: 0.0296\n",
      "Epoch 5/15\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4s/step - accuracy: 0.9646 - loss: 0.1031\n",
      "Epoch 5: val_accuracy did not improve from 1.00000\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m49s\u001B[0m 6s/step - accuracy: 0.9652 - loss: 0.1047 - val_accuracy: 1.0000 - val_loss: 1.0586e-04\n",
      "Epoch 5: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Plotting results...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T11:21:38.155850Z",
     "start_time": "2025-12-26T11:21:38.150810Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# --- 4. PREDICTION ---\n",
    "def prediction(model_path):\n",
    "    model = load_model(model_path)\n",
    "    rootdir = './test_224/'\n",
    "    test_labels = []\n",
    "    test_images = []\n",
    "\n",
    "    # Walk directories\n",
    "    for subdir, dirs, files in os.walk(rootdir):\n",
    "        for file in files:\n",
    "            if file.lower().endswith((\".jpeg\", \".jpg\", \".png\")):\n",
    "                label_name = subdir.split('/')[-1]\n",
    "                test_labels.append(label_name)\n",
    "                test_images.append(os.path.join(subdir, file))\n",
    "\n",
    "    predict_results = []\n",
    "    class_indices = {name: i for i, name in enumerate(class_names)}\n",
    "    index_to_label = {v: k for k, v in class_indices.items()}\n",
    "\n",
    "    print(f\"Predicting {len(test_images)} images...\")\n",
    "\n",
    "    for img_path in test_images:\n",
    "        try:\n",
    "            img = Image.open(img_path)\n",
    "            img = img.resize(TARGET_SIZE)\n",
    "            img_array = np.array(img) / 255.0  # Normalize\n",
    "            img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "            # Predict\n",
    "            pred_probs = model.predict(img_array, verbose=0)\n",
    "            pred_class_id = np.argmax(pred_probs, axis=1)[0] # Returns integer index\n",
    "\n",
    "            predict_results.append(index_to_label[pred_class_id])\n",
    "        except Exception as e:\n",
    "            print(f\"Error on {img_path}: {e}\")\n",
    "            predict_results.append(\"error\")\n",
    "\n",
    "    return accuracy_score(test_labels, predict_results)"
   ],
   "id": "c43ca626ae219857",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T11:21:38.204125Z",
     "start_time": "2025-12-26T11:21:38.200278Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# --- 5. HYPEROPT ---\n",
    "def objective(params):\n",
    "    print(f\"Testing: {params}\")\n",
    "    try:\n",
    "        vgg16(num_class=NUM_CLASSES,\n",
    "              frozen=int(params['frozen']),\n",
    "              epochs=int(params['epochs']),\n",
    "              patience=int(params['patience']),\n",
    "              lr=params['lr'],\n",
    "              dropout_rate=params['dropout_rate'],\n",
    "              verbose=0)\n",
    "\n",
    "        acc = prediction('./VGG16.h5')\n",
    "        print(f'Accuracy: {acc}')\n",
    "        return {'loss': -acc, 'status': STATUS_OK}\n",
    "    except Exception as e:\n",
    "        print(f\"Trial failed: {e}\")\n",
    "        return {'loss': 0, 'status': STATUS_OK} # Fail gracefully\n",
    "\n",
    "space = {\n",
    "    'frozen': hp.quniform('frozen', 15, 18, 1),\n",
    "    'epochs': hp.quniform('epochs', 5, 8, 1),\n",
    "    'patience': hp.quniform('patience', 2, 4, 1),\n",
    "    'lr': hp.loguniform('lr', np.log(0.0001), np.log(0.01)),\n",
    "    'dropout_rate': hp.uniform('dropout_rate', 0.3, 0.6),\n",
    "}"
   ],
   "id": "4abd98f1ffad5335",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T11:30:13.052179Z",
     "start_time": "2025-12-26T11:21:38.226212Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Run\n",
    "t1 = time.time()\n",
    "best = fmin(fn=objective, space=space, algo=tpe.suggest, max_evals=2)\n",
    "print(f\"Best: {best}\")"
   ],
   "id": "c058a2792bb723ad",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing: {'dropout_rate': 0.4030958148904888, 'epochs': 7.0, 'frozen': 16.0, 'lr': 0.0003590163365412256, 'patience': 4.0}\n",
      "Loading weights from ./vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "Starting training for 7 epochs...                    \n",
      "Epoch 1/7                                            \n",
      "\n",
      "\u001B[1m1/9\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m43s\u001B[0m 5s/step - accuracy: 0.7188 - loss: 1.1193\n",
      "\u001B[1m2/9\u001B[0m \u001B[32m━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m30s\u001B[0m 4s/step - accuracy: 0.7578 - loss: 0.9997\n",
      "\u001B[1m3/9\u001B[0m \u001B[32m━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━\u001B[0m \u001B[1m26s\u001B[0m 4s/step - accuracy: 0.7691 - loss: 0.9399\n",
      "\u001B[1m4/9\u001B[0m \u001B[32m━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━\u001B[0m \u001B[1m21s\u001B[0m 4s/step - accuracy: 0.7799 - loss: 0.8809\n",
      "\u001B[1m5/9\u001B[0m \u001B[32m━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━\u001B[0m \u001B[1m17s\u001B[0m 4s/step - accuracy: 0.7865 - loss: 0.8484\n",
      "\u001B[1m6/9\u001B[0m \u001B[32m━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━\u001B[0m \u001B[1m13s\u001B[0m 4s/step - accuracy: 0.7951 - loss: 0.8108\n",
      "\u001B[1m7/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━\u001B[0m \u001B[1m8s\u001B[0m 4s/step - accuracy: 0.8046 - loss: 0.7739 \n",
      "\u001B[1m8/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m4s\u001B[0m 4s/step - accuracy: 0.8115 - loss: 0.7451\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4s/step - accuracy: 0.8181 - loss: 0.7178\n",
      "                                                     \r\n",
      "Epoch 1: val_accuracy improved from None to 1.00000, saving model to ./VGG16.h5\n",
      "\n",
      "  0%|          | 0/2 [00:48<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                     \r\n",
      "Epoch 1: finished saving model to ./VGG16.h5\n",
      "\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m49s\u001B[0m 5s/step - accuracy: 0.8711 - loss: 0.4996 - val_accuracy: 1.0000 - val_loss: 0.0369\n",
      "\n",
      "Epoch 2/7                                            \n",
      "\n",
      "\u001B[1m1/9\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m34s\u001B[0m 4s/step - accuracy: 0.9375 - loss: 0.1605\n",
      "\u001B[1m2/9\u001B[0m \u001B[32m━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m32s\u001B[0m 5s/step - accuracy: 0.9453 - loss: 0.1494\n",
      "\u001B[1m3/9\u001B[0m \u001B[32m━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━\u001B[0m \u001B[1m26s\u001B[0m 4s/step - accuracy: 0.9497 - loss: 0.1470\n",
      "\u001B[1m4/9\u001B[0m \u001B[32m━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━\u001B[0m \u001B[1m21s\u001B[0m 4s/step - accuracy: 0.9544 - loss: 0.1396\n",
      "\u001B[1m5/9\u001B[0m \u001B[32m━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━\u001B[0m \u001B[1m17s\u001B[0m 4s/step - accuracy: 0.9548 - loss: 0.1367\n",
      "\u001B[1m6/9\u001B[0m \u001B[32m━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━\u001B[0m \u001B[1m12s\u001B[0m 4s/step - accuracy: 0.9563 - loss: 0.1319\n",
      "\u001B[1m7/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━\u001B[0m \u001B[1m8s\u001B[0m 4s/step - accuracy: 0.9580 - loss: 0.1264 \n",
      "\u001B[1m8/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m4s\u001B[0m 4s/step - accuracy: 0.9584 - loss: 0.1234\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4s/step - accuracy: 0.9591 - loss: 0.1201\n",
      "                                                     \r\n",
      "Epoch 2: val_accuracy did not improve from 1.00000\n",
      "\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m47s\u001B[0m 5s/step - accuracy: 0.9652 - loss: 0.0941 - val_accuracy: 1.0000 - val_loss: 0.0097\n",
      "\n",
      "Epoch 3/7                                            \n",
      "\n",
      "\u001B[1m1/9\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m32s\u001B[0m 4s/step - accuracy: 0.9688 - loss: 0.0561\n",
      "\u001B[1m2/9\u001B[0m \u001B[32m━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m28s\u001B[0m 4s/step - accuracy: 0.9688 - loss: 0.0623\n",
      "\u001B[1m3/9\u001B[0m \u001B[32m━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━\u001B[0m \u001B[1m24s\u001B[0m 4s/step - accuracy: 0.9722 - loss: 0.0587\n",
      "\u001B[1m4/9\u001B[0m \u001B[32m━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━\u001B[0m \u001B[1m20s\u001B[0m 4s/step - accuracy: 0.9753 - loss: 0.0540\n",
      "\u001B[1m5/9\u001B[0m \u001B[32m━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━\u001B[0m \u001B[1m17s\u001B[0m 4s/step - accuracy: 0.9777 - loss: 0.0525\n",
      "\u001B[1m6/9\u001B[0m \u001B[32m━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━\u001B[0m \u001B[1m12s\u001B[0m 4s/step - accuracy: 0.9797 - loss: 0.0503\n",
      "\u001B[1m7/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━\u001B[0m \u001B[1m8s\u001B[0m 4s/step - accuracy: 0.9813 - loss: 0.0479 \n",
      "\u001B[1m8/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m4s\u001B[0m 4s/step - accuracy: 0.9827 - loss: 0.0459\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4s/step - accuracy: 0.9838 - loss: 0.0440\n",
      "                                                     \r\n",
      "Epoch 3: val_accuracy did not improve from 1.00000\n",
      "\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m49s\u001B[0m 6s/step - accuracy: 0.9930 - loss: 0.0286 - val_accuracy: 1.0000 - val_loss: 7.7204e-04\n",
      "\n",
      "Epoch 4/7                                            \n",
      "\n",
      "\u001B[1m1/9\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m32s\u001B[0m 4s/step - accuracy: 1.0000 - loss: 0.0165\n",
      "\u001B[1m2/9\u001B[0m \u001B[32m━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m27s\u001B[0m 4s/step - accuracy: 1.0000 - loss: 0.0136\n",
      "\u001B[1m3/9\u001B[0m \u001B[32m━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━\u001B[0m \u001B[1m24s\u001B[0m 4s/step - accuracy: 1.0000 - loss: 0.0118\n",
      "\u001B[1m4/9\u001B[0m \u001B[32m━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━\u001B[0m \u001B[1m19s\u001B[0m 4s/step - accuracy: 1.0000 - loss: 0.0106\n",
      "\u001B[1m5/9\u001B[0m \u001B[32m━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━\u001B[0m \u001B[1m16s\u001B[0m 4s/step - accuracy: 1.0000 - loss: 0.0100\n",
      "\u001B[1m6/9\u001B[0m \u001B[32m━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━\u001B[0m \u001B[1m12s\u001B[0m 4s/step - accuracy: 1.0000 - loss: 0.0094\n",
      "\u001B[1m7/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━\u001B[0m \u001B[1m8s\u001B[0m 4s/step - accuracy: 1.0000 - loss: 0.0088 \n",
      "\u001B[1m8/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m4s\u001B[0m 4s/step - accuracy: 1.0000 - loss: 0.0083\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4s/step - accuracy: 1.0000 - loss: 0.0079\n",
      "                                                     \r\n",
      "Epoch 4: val_accuracy did not improve from 1.00000\n",
      "\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m47s\u001B[0m 5s/step - accuracy: 1.0000 - loss: 0.0044 - val_accuracy: 1.0000 - val_loss: 1.3675e-04\n",
      "\n",
      "Epoch 5/7                                            \n",
      "\n",
      "\u001B[1m1/9\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m32s\u001B[0m 4s/step - accuracy: 1.0000 - loss: 0.0019\n",
      "\u001B[1m2/9\u001B[0m \u001B[32m━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m27s\u001B[0m 4s/step - accuracy: 1.0000 - loss: 0.0014\n",
      "\u001B[1m3/9\u001B[0m \u001B[32m━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━\u001B[0m \u001B[1m23s\u001B[0m 4s/step - accuracy: 1.0000 - loss: 0.0013\n",
      "\u001B[1m4/9\u001B[0m \u001B[32m━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━\u001B[0m \u001B[1m19s\u001B[0m 4s/step - accuracy: 1.0000 - loss: 0.0012\n",
      "\u001B[1m5/9\u001B[0m \u001B[32m━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━\u001B[0m \u001B[1m15s\u001B[0m 4s/step - accuracy: 1.0000 - loss: 0.0011\n",
      "\u001B[1m6/9\u001B[0m \u001B[32m━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━\u001B[0m \u001B[1m11s\u001B[0m 4s/step - accuracy: 1.0000 - loss: 0.0010\n",
      "\u001B[1m7/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━\u001B[0m \u001B[1m7s\u001B[0m 4s/step - accuracy: 1.0000 - loss: 9.6003e-04\n",
      "\u001B[1m8/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m3s\u001B[0m 4s/step - accuracy: 1.0000 - loss: 9.1596e-04\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4s/step - accuracy: 1.0000 - loss: 8.7987e-04\n",
      "                                                     \r\n",
      "Epoch 5: val_accuracy did not improve from 1.00000\n",
      "\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m45s\u001B[0m 5s/step - accuracy: 1.0000 - loss: 5.9114e-04 - val_accuracy: 1.0000 - val_loss: 3.8487e-05\n",
      "\n",
      "Epoch 5: early stopping                              \n",
      "\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "\n",
      "  0%|          | 0/2 [03:56<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 75 images...                              \n",
      "Accuracy: 1.0                                        \n",
      "Testing: {'dropout_rate': 0.4914142086751401, 'epochs': 5.0, 'frozen': 16.0, 'lr': 0.003155916324851319, 'patience': 2.0}\n",
      "Loading weights from ./vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "Starting training for 5 epochs...                                 \n",
      "Epoch 1/5                                                         \n",
      "\n",
      "\u001B[1m1/9\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m38s\u001B[0m 5s/step - accuracy: 0.4375 - loss: 1.3901\n",
      "\u001B[1m2/9\u001B[0m \u001B[32m━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m27s\u001B[0m 4s/step - accuracy: 0.5469 - loss: 2.0058\n",
      "\u001B[1m3/9\u001B[0m \u001B[32m━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━\u001B[0m \u001B[1m23s\u001B[0m 4s/step - accuracy: 0.5208 - loss: 3.4643\n",
      "\u001B[1m4/9\u001B[0m \u001B[32m━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━\u001B[0m \u001B[1m19s\u001B[0m 4s/step - accuracy: 0.5332 - loss: 3.8479\n",
      "\u001B[1m5/9\u001B[0m \u001B[32m━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━\u001B[0m \u001B[1m15s\u001B[0m 4s/step - accuracy: 0.5503 - loss: 3.9452\n",
      "\u001B[1m6/9\u001B[0m \u001B[32m━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━\u001B[0m \u001B[1m11s\u001B[0m 4s/step - accuracy: 0.5688 - loss: 3.9000\n",
      "\u001B[1m7/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━\u001B[0m \u001B[1m8s\u001B[0m 4s/step - accuracy: 0.5864 - loss: 3.8131 \n",
      "\u001B[1m8/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m4s\u001B[0m 4s/step - accuracy: 0.6005 - loss: 3.7171\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4s/step - accuracy: 0.6128 - loss: 3.6136\n",
      "                                                                  \r\n",
      "Epoch 1: val_accuracy improved from None to 0.96000, saving model to ./VGG16.h5\n",
      "\n",
      " 50%|█████     | 1/2 [05:03<04:17, 257.40s/trial, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                  \r\n",
      "Epoch 1: finished saving model to ./VGG16.h5\n",
      "\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m47s\u001B[0m 5s/step - accuracy: 0.7108 - loss: 2.7852 - val_accuracy: 0.9600 - val_loss: 0.1455\n",
      "\n",
      "Epoch 2/5                                                         \n",
      "\n",
      "\u001B[1m1/9\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m32s\u001B[0m 4s/step - accuracy: 0.8125 - loss: 0.6315\n",
      "\u001B[1m2/9\u001B[0m \u001B[32m━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m39s\u001B[0m 6s/step - accuracy: 0.8281 - loss: 0.5885\n",
      "\u001B[1m3/9\u001B[0m \u001B[32m━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━\u001B[0m \u001B[1m29s\u001B[0m 5s/step - accuracy: 0.8333 - loss: 0.5558\n",
      "\u001B[1m4/9\u001B[0m \u001B[32m━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━\u001B[0m \u001B[1m23s\u001B[0m 5s/step - accuracy: 0.8418 - loss: 0.5211\n",
      "\u001B[1m5/9\u001B[0m \u001B[32m━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━\u001B[0m \u001B[1m17s\u001B[0m 4s/step - accuracy: 0.8447 - loss: 0.5108\n",
      "\u001B[1m6/9\u001B[0m \u001B[32m━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━\u001B[0m \u001B[1m13s\u001B[0m 4s/step - accuracy: 0.8506 - loss: 0.4926\n",
      "\u001B[1m7/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━\u001B[0m \u001B[1m8s\u001B[0m 4s/step - accuracy: 0.8566 - loss: 0.4746 \n",
      "\u001B[1m8/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m4s\u001B[0m 4s/step - accuracy: 0.8594 - loss: 0.4634\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4s/step - accuracy: 0.8619 - loss: 0.4521\n",
      "                                                                  \r\n",
      "Epoch 2: val_accuracy improved from 0.96000 to 0.98667, saving model to ./VGG16.h5\n",
      "\n",
      " 50%|█████     | 1/2 [05:50<04:17, 257.40s/trial, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                  \r\n",
      "Epoch 2: finished saving model to ./VGG16.h5\n",
      "\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m47s\u001B[0m 5s/step - accuracy: 0.8815 - loss: 0.3618 - val_accuracy: 0.9867 - val_loss: 0.0601\n",
      "\n",
      "Epoch 3/5                                                         \n",
      "\n",
      "\u001B[1m1/9\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m36s\u001B[0m 5s/step - accuracy: 0.9062 - loss: 0.2227\n",
      "\u001B[1m2/9\u001B[0m \u001B[32m━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m35s\u001B[0m 5s/step - accuracy: 0.8984 - loss: 0.2364\n",
      "\u001B[1m3/9\u001B[0m \u001B[32m━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━\u001B[0m \u001B[1m28s\u001B[0m 5s/step - accuracy: 0.8906 - loss: 0.2422\n",
      "\u001B[1m4/9\u001B[0m \u001B[32m━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━\u001B[0m \u001B[1m22s\u001B[0m 4s/step - accuracy: 0.8887 - loss: 0.2377\n",
      "\u001B[1m5/9\u001B[0m \u001B[32m━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━\u001B[0m \u001B[1m17s\u001B[0m 4s/step - accuracy: 0.8847 - loss: 0.2430\n",
      "\u001B[1m6/9\u001B[0m \u001B[32m━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━\u001B[0m \u001B[1m12s\u001B[0m 4s/step - accuracy: 0.8857 - loss: 0.2392\n",
      "\u001B[1m7/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━\u001B[0m \u001B[1m8s\u001B[0m 4s/step - accuracy: 0.8873 - loss: 0.2341 \n",
      "\u001B[1m8/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m4s\u001B[0m 4s/step - accuracy: 0.8868 - loss: 0.2327\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4s/step - accuracy: 0.8866 - loss: 0.2307\n",
      "                                                                  \r\n",
      "Epoch 3: val_accuracy did not improve from 0.98667\n",
      "\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m46s\u001B[0m 5s/step - accuracy: 0.8850 - loss: 0.2153 - val_accuracy: 0.9600 - val_loss: 0.0645\n",
      "\n",
      "Epoch 4/5                                                         \n",
      "\n",
      "\u001B[1m1/9\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m33s\u001B[0m 4s/step - accuracy: 0.8750 - loss: 0.2040\n",
      "\u001B[1m2/9\u001B[0m \u001B[32m━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m27s\u001B[0m 4s/step - accuracy: 0.8750 - loss: 0.2039\n",
      "\u001B[1m3/9\u001B[0m \u001B[32m━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━\u001B[0m \u001B[1m23s\u001B[0m 4s/step - accuracy: 0.8819 - loss: 0.2089\n",
      "\u001B[1m4/9\u001B[0m \u001B[32m━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━\u001B[0m \u001B[1m20s\u001B[0m 4s/step - accuracy: 0.8880 - loss: 0.2070\n",
      "\u001B[1m5/9\u001B[0m \u001B[32m━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━\u001B[0m \u001B[1m16s\u001B[0m 4s/step - accuracy: 0.8892 - loss: 0.2098\n",
      "\u001B[1m6/9\u001B[0m \u001B[32m━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━\u001B[0m \u001B[1m12s\u001B[0m 4s/step - accuracy: 0.8929 - loss: 0.2055\n",
      "\u001B[1m7/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━\u001B[0m \u001B[1m8s\u001B[0m 4s/step - accuracy: 0.8961 - loss: 0.2008 \n",
      "\u001B[1m8/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m4s\u001B[0m 4s/step - accuracy: 0.8988 - loss: 0.1999\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4s/step - accuracy: 0.9011 - loss: 0.1987\n",
      "                                                                  \r\n",
      "Epoch 4: val_accuracy improved from 0.98667 to 1.00000, saving model to ./VGG16.h5\n",
      "\n",
      " 50%|█████     | 1/2 [07:22<04:17, 257.40s/trial, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                  \r\n",
      "Epoch 4: finished saving model to ./VGG16.h5\n",
      "\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m45s\u001B[0m 5s/step - accuracy: 0.9199 - loss: 0.1890 - val_accuracy: 1.0000 - val_loss: 0.0588\n",
      "\n",
      "Epoch 5/5                                                         \n",
      "\n",
      "\u001B[1m1/9\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m44s\u001B[0m 6s/step - accuracy: 1.0000 - loss: 0.1883\n",
      "\u001B[1m2/9\u001B[0m \u001B[32m━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m29s\u001B[0m 4s/step - accuracy: 0.9922 - loss: 0.1905\n",
      "\u001B[1m3/9\u001B[0m \u001B[32m━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━\u001B[0m \u001B[1m26s\u001B[0m 4s/step - accuracy: 0.9774 - loss: 0.1951\n",
      "\u001B[1m4/9\u001B[0m \u001B[32m━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━\u001B[0m \u001B[1m21s\u001B[0m 4s/step - accuracy: 0.9714 - loss: 0.1927\n",
      "\u001B[1m5/9\u001B[0m \u001B[32m━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━\u001B[0m \u001B[1m17s\u001B[0m 4s/step - accuracy: 0.9633 - loss: 0.1947\n",
      "\u001B[1m6/9\u001B[0m \u001B[32m━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━\u001B[0m \u001B[1m13s\u001B[0m 4s/step - accuracy: 0.9599 - loss: 0.1904\n",
      "\u001B[1m7/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━\u001B[0m \u001B[1m8s\u001B[0m 4s/step - accuracy: 0.9573 - loss: 0.1858 \n",
      "\u001B[1m8/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m4s\u001B[0m 4s/step - accuracy: 0.9544 - loss: 0.1841\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4s/step - accuracy: 0.9521 - loss: 0.1820\n",
      "                                                                  \r\n",
      "Epoch 5: val_accuracy did not improve from 1.00000\n",
      "\n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m49s\u001B[0m 5s/step - accuracy: 0.9338 - loss: 0.1659 - val_accuracy: 1.0000 - val_loss: 0.0255\n",
      "\n",
      "Restoring model weights from the end of the best epoch: 4.        \n",
      "\n",
      " 50%|█████     | 1/2 [08:11<04:17, 257.40s/trial, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 75 images...                                           \n",
      "Accuracy: 1.0                                                     \n",
      "100%|██████████| 2/2 [08:34<00:00, 257.41s/trial, best loss: -1.0]\n",
      "Best: {'dropout_rate': np.float64(0.4030958148904888), 'epochs': np.float64(7.0), 'frozen': np.float64(16.0), 'lr': np.float64(0.0003590163365412256), 'patience': np.float64(4.0)}\n"
     ]
    }
   ],
   "execution_count": 6
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
